import requests
import json
import os
import sys
import urllib.parse
from datetime import datetime, timedelta
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.dirname(current_dir)
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)
import config
import database

DEFAULT_CATEGORY = "Project"

CATEGORIES_MAP = {
    "Market": "ğŸ“ˆ å¸‚åœºåŠ¨æ€",
    "Bid": "ğŸ’° ä¸­æ ‡ä¿¡æ¯",
    "Project": "ğŸ—ï¸ é¡¹ç›®ä¿¡æ¯",
    "Equipment": "ğŸ› ï¸ è®¾å¤‡ä¿®é€ ",
    "R&D": "ğŸ”¬ ç§‘æŠ€ç ”å‘",
    "Regulation": "âš–ï¸ æŠ€æœ¯æ³•è§„"
}

def get_scheduler_log_path():
    """è·å–è°ƒåº¦æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
    return os.path.join(backend_dir, "scheduler", "scheduler.log")

def write_scheduler_log(message):
    """å†™å…¥è°ƒåº¦æ—¥å¿—å†…å®¹"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_msg = f"[{timestamp}] {message}\n"
    try:
        with open(get_scheduler_log_path(), "a", encoding="utf-8") as f:
            f.write(log_msg)
    except Exception:
        pass

def get_push_window(now):
    """è·å–æ¨é€çª—å£çš„æ—¶é—´èŒƒå›´
    
    æ—©æŠ¥: 00:00-08:00 -> æ˜¨å¤©18:00 åˆ° ä»Šå¤©08:00
    æ™šæŠ¥: 08:00-18:00 -> ä»Šå¤©08:00 åˆ° ä»Šå¤©18:00
    """
    label_prefix = f"{now.month}æœˆ{now.day}æ—¥"
    hour = now.hour
    if hour <= 8:
        start_dt = (now - timedelta(days=1)).replace(hour=18, minute=0, second=0, microsecond=0)
        end_dt = now.replace(hour=8, minute=0, second=0, microsecond=0)
        label = f"{label_prefix}æ—©æŠ¥"
    else:
        start_dt = now.replace(hour=8, minute=0, second=0, microsecond=0)
        end_dt = now.replace(hour=18, minute=0, second=0, microsecond=0)
        label = f"{label_prefix}æ™šæŠ¥"
    return start_dt, end_dt, label

def normalize_hot_title(title, max_len=10):
    """è§„èŒƒåŒ–çƒ­é—¨æ–°é—»æ ‡é¢˜é•¿åº¦ä¸æ ¼å¼"""
    if not title:
        return ""
    text = str(title).strip().replace("\n", " ").replace("\r", " ")
    if len(text) <= max_len:
        return text
    return text[:max_len]

def build_hot_news_titles(events, max_items=4, title_max_len=10):
    """æ„å»ºä»Šæ—¥çƒ­é—¨æ–°é—»æ ‡é¢˜åˆ—è¡¨"""
    seen_keys = set()
    titles = []
    has_more = False
    for e in events:
        article_id = e.get("article_id")
        article_url = e.get("article_url")
        dedup_key = article_id if article_id is not None else article_url
        if dedup_key in seen_keys:
            continue
        seen_keys.add(dedup_key)
        raw_title = e.get("title_cn") or e.get("project_name") or e.get("article_title")
        title = normalize_hot_title(raw_title, max_len=title_max_len)
        if not title:
            continue
        if len(titles) < max_items:
            titles.append(title)
        else:
            has_more = True
            break
    if has_more:
        titles.append("...")
    return titles

def parse_event_datetime(value):
    if not value:
        return None, False
    text = str(value).strip()
    if not text:
        return None, False
    try:
        if "T" in text:
            return datetime.fromisoformat(text), False
        if " " in text and ":" in text:
            return datetime.fromisoformat(text.replace(" ", "T")), False
        return datetime.strptime(text, "%Y-%m-%d"), True
    except Exception:
        return None, False

def filter_events_by_publish_window(events, start_dt, end_dt):
    filtered = []
    for e in events:
        pub_dt, date_only = parse_event_datetime(e.get("pub_date"))
        if not pub_dt:
            pub_dt, date_only = parse_event_datetime(e.get("created_at"))
        if not pub_dt:
            continue
        if date_only:
            if pub_dt.date() < start_dt.date() or pub_dt.date() > end_dt.date():
                continue
        else:
            if pub_dt < start_dt or pub_dt > end_dt:
                continue
        filtered.append(e)
    return filtered

def normalize_title_key(text):
    if not text:
        return ""
    t = str(text).lower()
    stopwords = [
        "é›†å›¢", "å…¬å¸", "è‚¡ä»½", "æœ‰é™", "æœ‰é™å…¬å¸",
        "è¾¾æˆ", "ç­¾è®¢", "ç­¾ç½²", "ä¿®æ”¹", "ä¿®è®¢", "åè®®",
        "åˆä½œ", "å®£å¸ƒ", "å…¬å‘Š"
    ]
    for w in stopwords:
        t = t.replace(w, "")
    t = "".join(ch for ch in t if ch.isalnum() or '\u4e00' <= ch <= '\u9fff')
    return t

def dedupe_market_events(events):
    deduped_events = []
    seen_market = set()
    for e in events:
        if e.get("category") == "Market":
            title_key = normalize_title_key(e.get("title_cn") or e.get("article_title") or e.get("summary_cn"))
            if not title_key:
                title_key = e.get("article_url") or e.get("article_id")
            if title_key and title_key in seen_market:
                continue
            if title_key:
                seen_market.add(title_key)
        deduped_events.append(e)
    return deduped_events

def build_category_counts(events):
    buckets = {k: set() for k in CATEGORIES_MAP.keys()}
    for e in events:
        cat = e.get("category") or DEFAULT_CATEGORY
        if cat not in buckets:
            cat = DEFAULT_CATEGORY
        article_id = e.get("article_id")
        key = article_id if article_id is not None else e.get("article_url") or e.get("article_title")
        if key is None:
            continue
        buckets[cat].add(key)
    return {k: len(v) for k, v in buckets.items()}

def push_daily_report():
    """æ¨é€æ—¥æŠ¥åˆ°ä¼ä¸šå¾®ä¿¡"""
    now = datetime.now()
    start_dt, end_dt, label = get_push_window(now)
    start_time = start_dt.isoformat()
    end_time = end_dt.isoformat()
    
    events = database.get_events_by_time_range(start_time, end_time)
    raw_event_count = len(events)

    # Filter junk (Sync with dashboard.html logic)
    # è¿‡æ»¤æ‰æ— æ•ˆä¿¡æ¯ï¼Œç¡®ä¿æ¨é€æ•°é‡ä¸å‰ç«¯å±•ç¤ºä¸€è‡´
    valid_events = []
    for e in events:
        title = (e.get('title_cn') or e.get('article_title') or "").lower()
        cat = e.get('category', DEFAULT_CATEGORY)
        if "back to home" in title or "page not found" in title:
            continue
        valid_events.append(e)
    events = valid_events
    
    events = filter_events_by_publish_window(events, start_dt, end_dt)
    events = dedupe_market_events(events)
    filtered_event_count = len(events)

    if not events:
        print("æ— æ–°æƒ…æŠ¥ï¼Œå‘é€ç©ºæ¶ˆæ¯é€šçŸ¥")
        write_scheduler_log(f"æ¨é€ç»Ÿè®¡: çª—å£{label} åŸå§‹è®°å½•{raw_event_count} è¿‡æ»¤å0 æ¨é€0")
        if config.WECOM_WEBHOOK_URL:
            try:
                # å‘é€çº¯æ–‡æœ¬é€šçŸ¥
                payload = {
                    "msgtype": "text",
                    "text": {
                        "content": f"ã€å…¨çƒç–æµšæƒ…æŠ¥ {label}ã€‘\næˆªè‡³ç›®å‰ï¼Œæš‚æ— æœ€æ–°æƒ…æŠ¥æ›´æ–°ã€‚"
                    }
                }
                requests.post(config.WECOM_WEBHOOK_URL, json=payload)
                print("[Push] å·²å‘é€æ— æƒ…æŠ¥é€šçŸ¥")
            except Exception as e:
                print(f"[Push] å‘é€ç©ºæ¶ˆæ¯å¤±è´¥: {e}")
        return

    # æœ€ç»ˆå†³å®šï¼šç›´æ¥ä½¿ç”¨æœåŠ¡å™¨ä¸Šçš„é™æ€èµ„æº (å‡è®¾æœåŠ¡å™¨é…ç½®æ­£ç¡®)
    # å¦‚æœæ˜¯åœ¨æœ¬åœ°æµ‹è¯•ï¼Œè¿™ä¸ªé“¾æ¥å¯èƒ½æ— æ³•è¢«å¤–ç½‘è®¿é—®ï¼Œä½†ä¸å½±å“æµç¨‹
    cover_image_url = f"{config.BACKEND_URL.rstrip('/')}/assets/draghead.png"
    
    found_cover = False
    for e in events:
        if not found_cover and e.get('screenshot_path'):
            if "127.0.0.1" in config.BACKEND_URL or "localhost" in config.BACKEND_URL:
                pass
            else:
                filename = os.path.basename(e['screenshot_path'])
                encoded_filename = urllib.parse.quote(filename)
                cover_image_url = f"{config.BACKEND_URL.rstrip('/')}/assets/{encoded_filename}"
                found_cover = True

    # 2. æ„é€  Template Card
    date_str = label
    unique_article_ids = {e.get("article_id") for e in events if e.get("article_id") is not None}
    total_count = len(unique_article_ids)
    category_counts = build_category_counts(events)
    category_labels = {
        "Market": "å¸‚åœº",
        "Bid": "ä¸­æ ‡",
        "Project": "é¡¹ç›®",
        "Equipment": "è®¾å¤‡",
        "R&D": "ç ”å‘",
        "Regulation": "æ³•è§„"
    }
    category_line = " | ".join([f"{category_labels[k]}{category_counts.get(k, 0)}" for k in category_labels.keys()])
    write_scheduler_log(
        f"æ¨é€ç»Ÿè®¡: çª—å£{label} åŸå§‹è®°å½•{raw_event_count} è¿‡æ»¤å{filtered_event_count} æ¨é€{total_count}"
    )


    # æ„é€ è·³è½¬é“¾æ¥ (å¦‚æœæ²¡æœ‰é…ç½®å…¬ç½‘ IPï¼Œä½¿ç”¨ localhost ä¹Ÿæ²¡ç”¨ï¼Œä½†å¯ä»¥ä½œä¸ºå ä½)
    # ä½¿ç”¨ mode=recent å‚æ•°ï¼Œç¡®ä¿ç”¨æˆ·ç‚¹å‡»åçœ‹åˆ°çš„æ˜¯æ¨é€ç»Ÿè®¡çš„â€œæœ€è¿‘24å°æ—¶â€æ•°æ®ï¼Œè€Œä¸æ˜¯è‡ªç„¶æ—¥æ•°æ®
    jump_url = f"{config.BACKEND_URL.rstrip('/')}/?mode=recent"
    if "127.0.0.1" in jump_url:
        # æç¤ºç”¨æˆ·åœ¨æœ¬åœ°
        pass

    payload = {
        "msgtype": "template_card",
        "template_card": {
            "card_type": "news_notice",
            "source": {
                "icon_url": "https://cdn-icons-png.flaticon.com/512/2942/2942544.png",
                "desc": "å…¨çƒç–æµšæƒ…æŠ¥",
                "desc_color": 0
            },
            "main_title": {
                "title": f"{date_str}",
                "desc": f"æœ¬æ¬¡æ›´æ–°: {total_count} æ¡"
            },
            "card_image": {
                "url": cover_image_url,
                "aspect_ratio": 1.3
            },
            "vertical_content_list": [
                {
                    "title": "åˆ†ç±»åˆ†å¸ƒ",
                    "desc": category_line
                }
            ],
            "card_action": {
                "type": 1,
                "url": jump_url,
                "appid": "APPID",
                "pagepath": "PAGEPATH"
            }
        }
    }

    # 3. å‘é€
    if config.WECOM_WEBHOOK_URL:
        print(f"Pushing to: {config.WECOM_WEBHOOK_URL}")
        try:
            resp = requests.post(config.WECOM_WEBHOOK_URL, json=payload)
            print(f"[Push] å“åº”: {resp.text}")
            
            # å¦‚æœ Template Card å¤±è´¥ (ä¾‹å¦‚ errcode != 0)ï¼Œå°è¯•é™çº§ä¸º Text æ¶ˆæ¯
            resp_json = resp.json()
            if resp_json.get("errcode") != 0:
                print("Template Card æ¨é€å¤±è´¥ï¼Œå°è¯•é™çº§ä¸º Text æ¶ˆæ¯...")
                text_content = f"ã€å…¨çƒç–æµšæƒ…æŠ¥ {date_str}ã€‘\n"
                text_content += f"æœ¬æ¬¡æ›´æ–°: {total_count} æ¡\n\n"
                text_content += f"{category_line}\n"
                text_content += f"\nè¯¦æƒ…è¯·è®¿é—®: {jump_url}"
                
                text_payload = {
                    "msgtype": "text",
                    "text": {
                        "content": text_content
                    }
                }
                requests.post(config.WECOM_WEBHOOK_URL, json=text_payload)
                
        except Exception as e:
            print(f"[Push] å‘é€å¤±è´¥: {e}")
    else:
        print("[Push] æœªé…ç½® Webhook URLï¼Œè·³è¿‡å‘é€")

if __name__ == "__main__":
    push_daily_report()
